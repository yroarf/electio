import streamlit as st
import trafilatura
from urllib.parse import urljoin, urlparse
from groq import Groq
import os
import pandas as pd
from lxml import html
from bs4 import BeautifulSoup
import json
import matplotlib.pyplot as plt
import re
from groq.types.chat import ChatCompletionUserMessageParam
from playwright.sync_api import sync_playwright, TimeoutError as PWTimeoutError


os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†
#        CONFIGURAÃ‡ÃƒO DA PÃGINA DO APLICATIVO
# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†


st.set_page_config(
    page_title=" Analisador de Conformidade",
    page_icon="ğŸ—³ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)
# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†
#        VALIDAÃ‡ÃƒO DA CHAVE DA API DO GROQ
# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†


if "GROQ_API_KEY" not in st.session_state:
    api_key = st.secrets.get("GROQ_API_KEY") or os.getenv("GROQ_API_KEY")
    if not api_key:
        st.error("Chave da API do Groq nÃ£o encontrada. Configure em secrets ou variÃ¡vel de ambiente.")
        st.stop()
    st.session_state.GROQ_API_KEY = api_key

client = Groq(api_key=st.session_state.GROQ_API_KEY)

# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”  LISTA DE MODELOS DE IA â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†

# Ã‰ possÃ­vel incluir mais modelos que estÃ£o disponÃ­veis no site

GROQ_MODELS = [
    "llama-3.3-70b-versatile",
    "mixtral-8x7b-32768",
    "openai/gpt-oss-120b"
]

# â—†â”â”â”â”  CAMINHOS IRRELEVANTES PARA A BUSCA DE LINKS â”â”â”â”â”â”â”â—†

LISTA_1 = [
    '/login', '/cadastro', '/conta', '/privacidade',
    '/contato', '/sobre', '/equipe', '/assinatura',
    '/webmail', '/galeria', '/simbolos'
          ]  # palavras-chave para exclusÃ£o na busca de links

# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†
#                 CABEÃ‡ALHO DA PÃGINA
# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†

col_titulo, col_data = st.columns(2)
with col_titulo:
    st.title("ğŸ—³ï¸ Analisador de Conformidade Normativa")
with col_data:
    st.markdown("**Data de referÃªncia**")
    data_referencia = st.date_input(
        label="PerÃ­odo eleitoral de referÃªncia",
        value=None,  # sem valor padrÃ£o fixo â†’ usuÃ¡rio deve escolher
        min_value=None,
        max_value=None,
        help="Selecione a data do primeiro turno).",
        format="DD/MM/YYYY"
    )
if data_referencia is not None:
    st.session_state.data_referencia = data_referencia
    st.caption(f"Data selecionada: **{data_referencia.strftime('%d/%m/%Y')}**")
else:
    st.session_state.data_referencia = None
    col_espaco, colAtivacaoDATA =st.columns(2)
    with colAtivacaoDATA:
        st.info("Selecione uma data de referÃªncia para ativar a anÃ¡lise contextualizada no perÃ­odo do defeso eleitoral.")

st.markdown("### Compare conteÃºdo de notÃ­cias de sites institucionais com normas eleitorais")

st.markdown("""
<hr style="border: 3px solid #666; margin: 20px 0;">
""", unsafe_allow_html=True)

# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†
#            SELEÃ‡ÃƒO E CONFIGURAÃ‡Ã•ES DA IA
# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†

if "modeloIA" not in st.session_state:
    st.session_state.modeloIA = GROQ_MODELS[0]

st.markdown("### IA (LLM)")

with st.expander("ğŸ¤– **ConfiguraÃ§Ãµes do Modelo de IA**", expanded=False):
    col_model1, col_model2 = st.columns(2)
    with col_model1:
        # seleciona o modelo de IA
        modeloIA = st.selectbox(
            "Selecione o Modelo de IA (Groq)",
            options=GROQ_MODELS,
            index=0
        )
        modeloIA = st.session_state.modeloIA
    with col_model2:
        # Define o mÃ¡ximo de links por URL que serÃ£o pesquisados
        max_links = st.slider("NÃºmero mÃ¡ximo de LINKS por URL", 1, 20, 5, help="Quantos links internos por site.")

    col_temp, col_caract = st.columns(2)
    with col_temp:
        # Define a temperatura para a LLM considerar a anÃ¡lise mais flexÃ­vel (criativa) ou rÃ­gida (estatÃ­stica)
        temperatura = st.slider("Temperatura (criatividade)", 0.0, 2.0, 0.1, 0.1, help="O valor 0.0 Ã© determinÃ­stico.")
    with col_caract:
        # Define o nÃºmero mÃ¡ximo de caracteres lidos para cada trecho da lido
        quant_caract = st.slider("Quantidade mÃ­nima de caracteres", 100, 500, 250, 50, help="Valores menores aumentam a quantidade de trechos para anÃ¡lise.")

# â—†â”â”â”â”â”â”â”â”â”â”â”â”   ADIÃ‡ÃƒO DE SITES   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†

# Podem ser adicionado mais de um site

st.markdown("### AdiÃ§Ã£o de Sites")

if "sites_df" not in st.session_state:
    st.session_state.sites_df = pd.DataFrame(columns=["URL", "Nome do Site"]) # monta a tabela com a lista das URLs

# â—†â”â”â”â”â”â” EXTRAÃ‡ÃƒO DO SUBDOMÃNIO: MUN.UF.GOV.BR OU UF.GOV.BR â”â”â”â”â”â”â—†

def extrair_subdominio_gov(url: str) -> str:   # extrai o subdominio para facilitar a visualizaÃ§Ã£o

    parsed = urlparse(url.strip()) # limpa os espaÃ§os e desmonta a URL
    netloc = parsed.netloc.lower()

    if ':' in netloc:
        netloc = netloc.split(':')[0]
    if netloc.startswith('www.'):
        netloc = netloc[4:]
    if not netloc.endswith('.gov.br'):
        raise ValueError(f"A URL nÃ£o termina com .gov.br: {url}")
    dominio_sem_gov = netloc[:-7]
    partes = dominio_sem_gov.split('.')
    if len(partes) >= 2:
        resultado = '.'.join(partes[-2:])
    else:
        resultado = partes[-1]
    return resultado

# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” ADIÃ‡ÃƒO DE NOVO SITE â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†

with st.expander("ğŸŒ sites", expanded=False):
    st.markdown("##### Adicionar novo site")
    col1, col2 = st.columns([3, 1])
    with col1:
        nova_url = st.text_input(
            "URL do site (ex: https://www.municipio.uf.gov.br/noticias)",
            placeholder="https://www.exemplo.go.gov.br/noticias -* https:// *- Ã© mandatÃ³rio",
            help="PÃ¡gina principal de notÃ­cias ou comunicados da administraÃ§Ã£o pÃºblica."
        )

    if st.button("Adicionar Site", type="primary"):
        if not nova_url.strip():
            st.error("Por favor, insira uma URL vÃ¡lida.")
        else:
            url_limpa = nova_url.strip().rstrip("/")
            # Monta o dataframe com as URL/PATH
            urls_existentes = st.session_state.sites_df["URL"].str.rstrip("/").tolist()

            if url_limpa in urls_existentes:
                st.error("Esta URL jÃ¡ foi adicionada.")
            else:
                nome_exibicao = urlparse(url_limpa).netloc
                novo_site = pd.DataFrame([{
                    "URL": url_limpa,
                    "Nome do Site": nome_exibicao
                }])
                st.session_state.sites_df = pd.concat(
                    [st.session_state.sites_df, novo_site],
                    ignore_index=True
                )
                st.success(f"Site adicionado: {nome_exibicao}")
                st.rerun()

# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” LISTA EDITÃVEL DE SITES â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†

    st.markdown("##### Lista de Sites para AnÃ¡lise")

    if st.session_state.sites_df.empty:
        st.info("Nenhum site adicionado ainda. Use o campo acima para incluir.")
    else:
        # Aqui sÃ£o apresentadas as URLs em uma tabela
        # data_editor com validaÃ§Ã£o de duplicatas e com possibilidade de ediÃ§Ã£o
        edited_df = st.data_editor(
            st.session_state.sites_df,
            num_rows="dynamic",
            use_container_width=True,
            column_config={
                "URL": st.column_config.TextColumn(
                    "URL",
                    required=True,
                    help="URL completa da pÃ¡gina de notÃ­cias"
                ),
                "Nome do Site": st.column_config.TextColumn(
                    "Nome do Site",
                    required=False,
                    help="Nome amigÃ¡vel para exibiÃ§Ã£o"
                )
            },
            hide_index=True
        )

        # ValidaÃ§Ã£o: impedir URLs duplicadas ao editar
        urls_editadas = edited_df["URL"].str.strip().str.rstrip("/").tolist()
        if len(urls_editadas) != len(set(urls_editadas)):
            st.error("âš ï¸ AtenÃ§Ã£o: NÃ£o Ã© permitido ter URLs duplicadas na lista.")
        else:
            # SÃ³ atualiza o estado se nÃ£o houver duplicatas
            st.session_state.sites_df = edited_df
            st.success("Lista atualizada com sucesso!")
        # print(edited_df)
        st.caption(f"Total de sites: **{len(st.session_state.sites_df)}**")


# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ BASE LEGAL â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘


#Esse trecho do cÃ³digo Ã© dedicado ao carregamento da normatizaÃ§Ã£o aplicÃ¡vel.
#A estrutura separada visa dimininuir a latÃªncia e reduzir a quantidade de tokens
#utilizados.
#A base de dados Ã© trabalhada no mesmo ambiente de anÃ¡lise dos sites visando estabelecer
#uma conexÃ£o com o prompt de anÃ¡lise de conformidade dos conteÃºdos dos sites.


@st.cache_data(ttl=3600) #decorator para carregar os dados na memÃ³ria cache e evitar execuÃ§Ãµes repetidas
def analisar_base_legal(base_legal: str, data_referencia: str, modeloIA: str) -> str:
    if not base_legal.strip():
        return "Nenhuma base legal fornecida."

    prompt_base_legal = f"""
    VocÃª Ã© um jurista especializado em Direito Eleitoral.

    Dada a base legal completa de referÃªncia e considerando a data de referÃªncia do pleito \"\"\"{data_referencia}\"\"\",

    Gere uma anÃ¡lise ESTRUTURADA, Densa e HierÃ¡rquica destacando as vedaÃ§Ãµes, proibiÃ§Ãµes e condutas vedadas aos
    agentes pÃºblicos no perÃ­odo eleitoral, com base na data de referÃªncia informada pelo usuÃ¡rio.
    
    Calcule as datas para os perÃ­odos de defeso eleitoral que antecedem o primeiro pleito, considerando o primeiro perÃ­odo 6 meses que antecedem
    o pleito e o segundo perÃ­odo com 3 meses que antecedem o pleito. 
    
    ** Considere rigorosamente as condutas vedadas em funÃ§Ã£o das datas que antecedem a data de referÃªncia por 6 e 3 meses, 
    analisando e identificando vedaÃ§Ãµes como propaganda institucional, uso de bens pÃºblicos, etc, atreladas ao perÃ­odo de
    defeso eleitoral.

    Estrutura obrigatÃ³ria da anÃ¡lise (use exatamente este formato markdown para facilitar parsing):
    - **ParÃ¡grafos com as VedaÃ§Ãµes principais** (liste com bullets numerados ou -)
    - **IndicaÃ§Ãµes dos PerÃ­odos de incidÃªncia** (datas relativas Ã  eleiÃ§Ã£o)
    - **ParÃ¡grafos destacanto as ExceÃ§Ãµes e condutas permitidas**
    - **ParÃ¡grafos indicandos as SanÃ§Ãµes tÃ­picas** (breve)

    A anÃ¡lise nÃ£o deve prejudicar a compreensÃ£o do conteÃºdo legal, por isso, alÃ©m de completo, deve ser
    o mais fiel possÃ­vel ao texto da base legal carregada pelo usuÃ¡rio, SOMENTE ELIMINE redundÃ¢ncias e linguagem prolixa.
     
    Deixe bem claras as vedaÃ§Ãµes correspondentes aos prazos de 3 e 6 meses do defeso eleitoral que 
    antecedem a data do primeiro pleito (data_referencia).

    Base legal completa:
    \"\"\"{base_legal}\"\"\"

    Responda APENAS com o documento da anÃ¡lise estruturada, sem introduÃ§Ã£o nem conclusÃ£o.
    """
    # Carrega o prompt que serÃ¡ passado para anÃ¡lise pela LLM
    messages = [ChatCompletionUserMessageParam(role="user", content=prompt_base_legal)]

    #ParÃ¢metros utilizados pela LLM via API
    try:
        response = client.chat.completions.create(
            model=modeloIA,
            messages=messages,
            temperature=0.1,  # baixa criatividade para fidelidade
            max_tokens=1000
        )
        print(response)
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.warning(f"Erro ao resumir base legal: {e}")
        return base_legal[:8000] + " [resumo truncado devido a erro]"

# inclui a variÃ¡vel conteudo_base_legal na seÃ§Ã£o do streamlit
if "conteudo_base_legal" not in st.session_state:
    st.session_state.conteudo_base_legal = ""

st.markdown("### **Base Legal**")
with st.expander("ğŸ“‹ Base Legal", expanded=False):
    st.markdown("Defina o texto de referÃªncia legal que serÃ¡ usado na anÃ¡lise de conformidade pelo LLM.")

    # Carregar mÃºltiplos TXT como referÃªncia

    st.markdown("### Upload arquivos .txt")
    st.markdown("**Carregue atÃ© 2 arquivos .txt** com trechos da lei, resoluÃ§Ã£o, portaria, cartilha etc.")

    # faz upload de arquivos do usuÃ¡rio em formato txt
    uploaded_txt_files = st.file_uploader(
        "Selecione arquivos TXT",
        type=["txt"],
        accept_multiple_files=True,
        key="txt_referencia_multi",
        help="MÃ¡ximo de 2 arquivos. Todos serÃ£o combinados em um Ãºnico texto para a anÃ¡lise."
    )

    conteudo_base_legal_referencia = "" #declara como str

    if uploaded_txt_files:
        if len(uploaded_txt_files) > 2:
            st.error("Limite mÃ¡ximo: 2 arquivos TXT.")
            uploaded_txt_files = uploaded_txt_files[:2]

        textos_carregados = []
        for file in uploaded_txt_files:
            try:
                contenteudo_txt = file.read().decode("utf-8") # carrega o arquivo com conteÃºdo normativo .txt na variÃ¡vel
                # junta os conteÃºdo para formar a base legal
                textos_carregados.append(f"\n\n=== ConteÃºdo de: {file.name} ===\n{contenteudo_txt}") #lista de conteÃºdos
            except Exception as e:
                st.warning(f"Erro ao ler {file.name}: {e}")

        if textos_carregados:
            conteudo_base_legal_referencia = "\n".join(textos_carregados) #transfoma a lista textos_carregados em um sÃ³ conteÃºdo
            st.success(f"{len(textos_carregados)} arquivo(s) TXT carregado(s) com sucesso.")
            st.caption(f"Total de caracteres: {len(conteudo_base_legal_referencia):,}")

        # Campo opcional para texto manual
        st.markdown("**Ou cole texto diretamente (opcional)**")
        texto_manual = st.text_area(
            "Texto adicional ou complementar.",
            height=150,
            placeholder="Cole aqui trechos especÃ­ficos de julgados, artigos, doutrina etc."
        )

        # Texto final consolidado para a LLM
        # aqui a variÃ¡vel conteudo_base_legal recebe os valores de conteudo_base_legal_referencia ou texto_manual
        if conteudo_base_legal_referencia or texto_manual.strip():
            st.session_state.conteudo_base_legal = conteudo_base_legal_referencia
            if texto_manual.strip():
                st.session_state.conteudo_base_legal += "\n\n" + texto_manual.strip()
            st.info("Texto de referÃªncia pronto.")

            if st.button("AnÃ¡lise da Base Legal"):
                with st.spinner("Analisando a base legal..."):
                    analise_bl = analisar_base_legal(
                        st.session_state.conteudo_base_legal,
                        st.session_state.data_referencia.strftime('%d/%m/%Y') if st.session_state.data_referencia else "nÃ£o informada",
                        modeloIA
                    )
                    st.session_state.analise_bl = analise_bl
                    st.success("AnÃ¡lise gerada!")
                    st.markdown("**AnÃ¡lise gerada:**")
                    st.markdown(analise_bl)



# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ FUNÃ‡Ã•ES AUXILIARES â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘

# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” FUNÃ‡ÃƒO PARA COLETA DE LINKS DO SITE â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†

def coletar_links_internos(url: str, max_links) -> set:
    downloaded = trafilatura.fetch_url(url)  # web scraping
    if not downloaded:
        return {url}
    try:
        tree = html.fromstring(downloaded) # converte em uma Ã¡rvore de dados hierÃ¡rquicos
    except Exception:
        return {url}

    dominio = urlparse(url).netloc # extrai a parte da rede de uma URL
    links_validos = {url}

    #Loop para interar sobre todos os atributos href das tags de Ã¢ncora (<a>) do tree.
    for href in tree.xpath("//a/@href"): #
        full = urljoin(url, href.strip())
        parsed = urlparse(full)

        if parsed.netloc != dominio: # Verifica se o domÃ­nio da URL extraÃ­da Ã© o mesmo que o domÃ­nio da pÃ¡gina original
            continue                 # se for diferente, ignora o link e nÃ£o coleta o link externo.

        path = parsed.path.lower()

        if any(block in path for block in LISTA_1): # se verdadeiro ignora e nÃ£o coleta o link
            continue

        if re.search(r'\.(pdf|jpg|jpeg|png|gif|zip|docx?|xlsx?)$', path): # se verdadeiro ignora e nÃ£o coleta o link
            continue

        links_validos.add(full)

        if len(links_validos) >= max_links:
            break

    return links_validos

# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” FUNÃ‡ÃƒO PARA EXTRAÃ‡ÃƒO DE TEXTO â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†

@st.cache_resource(ttl=3600 * 4)  # Reutiliza browser â†’ economia de recurso
def _get_playwright_browser():
    pw = sync_playwright().start()
    browser = pw.firefox.launch(headless=True, timeout=50000)
    return pw, browser

def extrair_texto(url: str, min_length) -> str:

    # ExtraÃ§Ã£o robusta para portais .gov.br:
    # Prioriza velocidade â†’ fallback playwright sÃ³ se necessÃ¡rio

    # Primeira tentativa -> leve e rÃ¡pida
    downloaded = trafilatura.fetch_url(url)
    if not downloaded:
        return tentar_playwright(url, min_length)

    # A. Trafilatura otimizado (melhor recall em notÃ­cias)
    text = trafilatura.extract(
        downloaded,
        favor_recall=True,
        favor_precision=True,
        include_comments=False,
        include_tables=False,
        include_formatting=False,
        output_format="txt",
        no_fallback=False
    )
    if text and len(text.strip()) >= quant_caract:
        return limpar_texto(text)

    try:
        soup = BeautifulSoup(downloaded, "lxml")
        for tag in soup(["script", "style", "noscript", "header", "footer", "nav", "aside", "form"]):
            tag.decompose()
        text = soup.get_text(separator="\n", strip=True)
        text = re.sub(r'\n{3,}', '\n\n', text).strip()
        if len(text) >= min_length:
            return limpar_texto(text)
    except:
        pass

    # Ãšltimo recurso: browser real (Playwright)
    return tentar_playwright(url, min_length)

def tentar_playwright(url: str, min_length: int) -> str:
    try:
        pw, browser = _get_playwright_browser()
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:133.0) Gecko/20100101 Firefox/133.0",
            locale="pt-BR",
            viewport={"width": 1280, "height": 900}
        )
        page = context.new_page()

        page.goto(url, wait_until="domcontentloaded", timeout=35000)
        try:
            page.wait_for_load_state("networkidle", timeout=18000)
        except:
            pass

        # Rolagem leve para lazy-load
        page.evaluate("window.scrollTo(0, document.body.scrollHeight);")
        page.wait_for_timeout(800)

        # Tenta clicar em botÃµes de aceite comuns
        for text in ["Aceitar", "Concordar", "OK", "Continuar", "Fechar", "Aceito"]:
            try:
                page.get_by_role("button", name=re.compile(text, re.I)).first.click(timeout=1800)
                break
            except:
                pass

        # Extrai via seleÃ§Ã£o de tags se conteÃºdo principais
        content = page.evaluate("""
            () => {
                const main = document.querySelector('article, main, [role="main"], #content, .entry-content, .post-content, .noticia-conteudo');
                return (main || document.body).innerText.trim();
            }
        """)

        page.close()
        context.close()

        if content and len(content) >= min_length:
            return limpar_texto(content)

    except (PWTimeoutError, Exception) as e:
        print(f"[PLAYWRIGHT falhou] {url} â†’ {str(e)[:90]}")

    finally:
        # NÃ£o fecha o browser global aqui â€” reutilizado via cache_resource
        pass

    return ""


def limpar_texto(text: str) -> str:
    if not text:
        return ""
    # Remove blocos comuns que vazam em .gov.br
    text = re.sub(r'(?is)(polÃ­tica de (cookies|privacidade|lgpd)|acessibilidade|transparÃªncia ativa|ouvidoria|contato).*?(?=\n{2,}|$)', '', text)
    text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
    return text.strip()

# â—†â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” FUNÃ‡ÃƒO PARA FILTRAR CONTEÃšDO IRRELEVANTE â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â—†

# O objetivo do Ã© filtrar os conteÃºdos que nÃ£o correspondem a conteÃºdos estruturais da pÃ¡gina

def filtrar_conteudo_relevante(texto: str) -> str:
    if not texto:
        return ""
    termos_irrelevantes = [
        "polÃ­tica de privacidade", "cookies", "lgpd", "acessibilidade", "navegaÃ§Ã£o", "teclas", "tab", "enter",
        "rolagem", "ctrl", "command", "razÃ£o social", "cnpj", "endereÃ§o", "contato", "login", "termos de uso",
        "sobre nÃ³s", "rodapÃ©", "footer", "header", "menu", "navegador", "privacidade", "seguranÃ§a", "captcha",
        "WhatsApp"
    ]
    # Remove seÃ§Ãµes inteiras que contenham palavras-chave
    blocos = re.split(r'\n\s*\n', texto)  # separa por parÃ¡grafos duplos
    blocos_filtrados = []
    for bloco in blocos:
        if not any(k.lower() in bloco.lower() for k in termos_irrelevantes): # o que nÃ£o estÃ¡ em bloco irrelevante passa.
            blocos_filtrados.append(bloco)
    return "\n\n".join(blocos_filtrados).strip()


# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ PROMPT PARA ANÃLISE DE CONTEÃšDO DOS SITES â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘

prompt_padrao = """
VocÃª Ã© um jurista especializado em compliance, com larga experiÃªncia em Direito Administrativo, Direito Eleitoral e 
Ã©tica na AdministraÃ§Ã£o PÃºblica Federal.

Atue de forma tÃ©cnica, objetiva, fundamentada e neutra, sem emitir juÃ­zos polÃ­ticos ou valorativos.
[/PERSONA]

[CONTEXTO]
Durante o perÃ­odo eleitoral, Ã© essencial que a AdministraÃ§Ã£o PÃºblica observe rigorosamente as normas legais e Ã©ticas aplicÃ¡veis
Ã s comunicaÃ§Ãµes institucionais, bem como as condutas que sÃ£o vedadas por lei, regulamento, norma etc. 

Para fins desta anÃ¡lise de conformidade, sÃ£o considerados, EXCLUSIVAMENTE: 
1 - O texto passado pelo usuÃ¡rio por meio da variÃ¡vel "texto";
2 - a data do pleito passada por meio da variÃ¡vel "data_referencia"; e 
3 - O RESUMO PRÃ‰VIO DA BASE LEGAL processado na etapa resumo da base legal.

[FLUXO]
Com base no texto, execute rigorosamente as seguintes etapas: 
1 - Divida o texto abaixo em trechos significativos (frases ou parÃ¡grafos com ideia completa e autÃ´noma).
2 - Analise a conformidade de cada trecho com relaÃ§Ã£o ao RESUMO PRÃ‰VIO DA BASE LEGAL.
3 - Observe rigorosamente a data de inÃ­cio do pleito (data de referÃªncia informada pelo usuÃ¡rio) e as vedaÃ§Ãµes correspondentes aos perÃ­odos de 3 e 6 meses que antecedem o pleito. As regras estÃ£o 
na resultado do processamento da base legal. 

RESUMO DA BASE LEGAL (referÃªncia Ãºnica para julgar conformidade):
\"\"\"{resumo_base_legal}\"\"\"

INSTRUÃ‡Ã•ES RESTRIÃ‡ÃƒO SOBRE ELEMENTOS OU TAGs DE CONTEÃšDOS EXTRAÃDOS â€“ Desconsidere trechos cujo header traz uma dos seguintes termos:
- Ignore completamente links ou trechos que iniciem ou contenha de forma estrutural do html os seguintes termos: 
  'polÃ­tica de privacidade', 'cookies', 'LGPD', 'acessibilidade', 
  'navegaÃ§Ã£o' '(TAB/ENTER/CTRL)', 'razÃ£o social', 'CNPJ', 'endereÃ§o', 'termos de uso', 'login'', 
  'contato', 'rodapÃ©', 'menu', 'header',  'footer', "Acesse", "ServiÃ§os", "Ã“rgÃ£o Vinculado", "Siga-nos" ou 
   qualquer elemento estrutural que nÃ£o seja um texto com nÃ£o-notÃ­cia.

- Foque apenas em notÃ­cias, comunicados ou textos institucionais relevantes.
- Divida o texto em trechos significativos (frases ou parÃ¡grafos com ideia completa e autÃ´noma).
- Classifique cada trecho como "conforme" ou "nÃ£o_conforme" com base no resumo. Seja muito rigoroso nessa parte, 
  os trechos com texto "conforme" Ã© considerado para efeito do total de trechos. Ou seja, 
  o total de trechos deve obrigatoriamente sempre ser igual a soma dos trechos conformes e nÃ£o conformes.
- AtenÃ§Ã£o na data de referencia informada pelo usuÃ¡rio, pois, a partir dela Ã© que se considera os perÃ­odos do defeso eleitoral. 
  NÃ£o negligencie essa parte, Ã© indispensÃ¡vel classificar a conformidade com relaÃ§Ã£o aos perÃ­odos de defeso. 
  Exemplo: eventos, acontecimentos ou aÃ§Ãµes anteriores aos perÃ­odos de defeso informados na base legal podem ser desconsiderados. 
- NÃƒO escreva NENHUM texto explicativo, introduÃ§Ã£o, conclusÃ£o, comentÃ¡rio ou palavra extra.
- Retorne EXATAMENTE cada trecho analisado para o processo de contagem, 
  sem aspas extras, sem JSON, sem formataÃ§Ã£o adicional.
_ Para cada trecho nÃ£o conforme adicione o trecho Ã  lista trechos_nao_conformes.
- Se nÃ£o houver nenhum techo nÃ£o conforme, faÃ§a a variÃ¡vel total_conformes ter o valor igual a total_trechos_analisados

---------------------- RESULTADO ---------------------------------

A resposta final tem apenas 2 variÃ¡veis, trechos_nao_conformes e contagem, e deve-se seguir rigorosamente os seguintes formatos:

trechos_nao_conformes = [["trecho1 nÃ£o conforme"], ["trecho2 nÃ£o conforme"], ...]

contagem = [total_trechos_analisados, total_conformes, total_nao_conformes]

Exemplos obrigatÃ³rios do formato exato (copie exatamente):
Se houver 2 nÃ£o conformes em 10 trechos (8 conformes):
trechos_nao_conformes = [["Texto do primeiro trecho nÃ£o conforme"], ["Texto do segundo trecho nÃ£o conforme"]]
contagem = [10, 8, 2]


Texto para anÃ¡lise:
\"\"\"{texto}\"\"\"

Data de referÃªncia:
\"\"\"{data_referencia}\"\"\"

Responda SOMENTE com as duas linhas acima. Nada mais.
"""

st.markdown("### **Prompt**")
with st.expander("ğŸ§  Prompt", expanded=False):
    st.markdown("#### Prompt para AnÃ¡lise")

    if "prompt_reset" not in st.session_state:
        st.session_state.prompt_reset = 0

    prompt_personalizado = st.text_area(
        "Edite o prompt que serÃ¡ enviado ao modelo",
        # a variÃ¡vel prompt_personalizado recebe o conteÃºdo do prompt_padrao, que pode ser editado pelo usuÃ¡rio
        value=prompt_padrao,
        height=350,
        key=f"prompt_editor_{st.session_state.prompt_reset}"
    )


# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ FUNÃ‡ÃƒO PARA ANÃLISE COM LLM - chamada da API do Groq â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘


def analisar_com_llm(texto: str,
                     model: str,
                     temperatura: float,
                     prompt_personalizado: str,
                     data_referencia):

    # extrai conteÃºdo relevante
    texto_filtrado = filtrar_conteudo_relevante(texto)
    if not texto_filtrado:
        return [], [0, 0, 0]

    data_ref_str = data_referencia.strftime('%d/%m/%Y') if data_referencia else "nÃ£o informada"

    try:
        prompt_completo = prompt_personalizado.format(
            texto=texto_filtrado,
            data_referencia=data_ref_str,
            # resumo_base_legal=st.session_state.get("resumo_base_legal", "Nenhum resumo disponÃ­vel")
            resumo_base_legal = st.session_state.get("resumo_base_legal")
        )
    except Exception as e:
        st.error(f"Erro no formato do prompt: {e}")
        return [], [0, 0, 0]

    try:
        messages = [ChatCompletionUserMessageParam(role="user", content=prompt_completo)]
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperatura,
            max_tokens=800
        )

        content = response.choices[0].message.content.strip()

        #print("=====================================content========================")
        #print(content)
        
        # Armazena os trechos nÃ£o conformes e realiza a contagem global
        
        trechos_nao_conformes = []
        contagem = [0, 0, 0]

        # ModificaÃ§Ã£o 1: ExpressÃ£o regular mais flexÃ­vel
        match_trechos = re.search(r'trechos_nao_conformes\s*=\s*(\[.*?])', content, re.DOTALL | re.IGNORECASE)
        if match_trechos:
            lista_str = match_trechos.group(1)
            # Limpar aspas e caracteres especiais
            lista_str = lista_str.replace('â€œ', '"').replace('â€', '"').replace("'", '"')
            # Remover quebras de linha dentro das strings
            lista_str = re.sub(r'\n', ' ', lista_str)
            try:
                lista_trechos = json.loads(lista_str)
                # Extrair strings das listas internas
                trechos_nao_conformes = []
                for item in lista_trechos:
                    if isinstance(item, list) and len(item) > 0:
                        trechos_nao_conformes.append(str(item[0]).strip())
                    elif isinstance(item, str):
                        trechos_nao_conformes.append(item.strip())
            except json.JSONDecodeError as e:
                print("Erro ao parsear trechos:", e, "\nConteÃºdo bruto:", lista_str)
                # Fallback: tentar extrair manualmente
                padrao_fallback = r'\[\s*"([^"]+)"\s*\]'
                trechos_encontrados = re.findall(padrao_fallback, lista_str)
                if trechos_encontrados:
                    trechos_nao_conformes = [t.strip() for t in trechos_encontrados]

        # ModificaÃ§Ã£o 2: ExpressÃ£o regular para contagem
        match_contagem = re.search(r'contagem\s*=\s*(\[\s*\d+\s*,\s*\d+\s*,\s*\d+\s*])', content, re.IGNORECASE)
        
        contagem = None
        contagem_str = None
        
        if match_contagem:
            try:
                contagem_str = match_contagem.group(1)
                contagem = json.loads(contagem_str)
            except:
                print("Erro ao parsear contagem:", match_contagem.group(1))
                # Fallback: extrair nÃºmeros
                numeros = re.findall(r'\d+', contagem_str)
                if len(numeros) >= 3:
                    contagem = [int(n) for n in numeros[:3]]

        return trechos_nao_conformes, contagem

    except Exception as e:
        st.warning(f"Erro na chamada ao LLM: {e}")
        return [], [0, 0, 0]



# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ ANÃLISE DOS SITES â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘


if "resultados" not in st.session_state:
    st.session_state.resultados = []

colAnalisar1, colAnalisar2, colAnalisar3 = st.columns([1, 2, 1])
with colAnalisar2:
    analisar = st.button("ğŸš€ **Analisar Sites**", type="primary", use_container_width=True)

if analisar:
    if st.session_state.sites_df.empty:
        st.error("Adicione pelo menos um site antes de analisar.")
    else:
        sites = st.session_state.sites_df.to_dict("records")  # ok
        resultados_analise_llm = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        # print(sites)
        for idx, site in enumerate(sites):
            url = site["URL"]
            status_text.text(f"Analisando {idx + 1}/{len(sites)}: {url}")
            # print(max_links)
            links = coletar_links_internos(url, max_links=max_links)

            total_trechos = 0
            total_conformes = 0
            total_nao_conformes = 0
            trechos_nao_conformes = []

            # print(links)
            for link in links:
                texto = extrair_texto(link, quant_caract)
                if texto:
                    trechos_nao_conformes_site, lista_contagem = analisar_com_llm(
                        texto,
                        modeloIA,
                        temperatura,
                        prompt_personalizado,
                        st.session_state.data_referencia
                    )
                    # Acumula os trechos (lista de strings)
                    trechos_nao_conformes.extend(trechos_nao_conformes_site)

                    # Acumula contagens
                    total_trechos += lista_contagem[0]
                    total_conformes += lista_contagem[1]
                    total_nao_conformes += lista_contagem[2]

            # Calcula percentual de conformidade da URL
            if total_trechos == 0:
                perConformes = 0.0
            else:
                perConformes = round((total_conformes / total_trechos) * 100, 1)

            resultados_analise_llm.append({

                "url": url,
                "conformidade": perConformes,
                "total_trechos": total_trechos,
                "conformes": total_conformes,
                "nao_coformes": total_nao_conformes,
                "trechos_nao_conformes": trechos_nao_conformes

            })
            print("_____________________resultados_analise_llm___________________")
            print(resultados_analise_llm)

            progress_bar.progress((idx + 1) / len(sites))

        status_text.empty()
        progress_bar.empty()
        st.session_state.resultados = resultados_analise_llm


# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ TABELA E GRÃFICO DE BARRAS DOS RESULTADOS â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
# â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘


resultados_para_plot = st.session_state.get("resultados", [])

if resultados_para_plot:
    def nome_grafico(url):
        return extrair_subdominio_gov(url)


    df_result = pd.DataFrame({
        "Site": [nome_grafico(r.get("url", "")) for r in resultados_para_plot],
        "Conformidade (%)": [float(r.get("conformidade", 0.0)) for r in resultados_para_plot]
        # chave correta Ã© "conformidade"
    })

    df_result = df_result.dropna(subset=["Site", "Conformidade (%)"])

    trechos_nao_conformes = []

    for resultado in resultados_para_plot:
        url = resultado.get("url", "â€”")
        nome_site = nome_grafico(url)
        trechos = resultado.get("trechos_nao_conformes", [])  # lista de strings

        for trecho in trechos:
            if isinstance(trecho, str) and trecho.strip():
                trechos_nao_conformes.append({
                    "Site": nome_site,
                    "Trecho": trecho.strip(),
                    "ClassificaÃ§Ã£o": "nao_conforme",
                    "URL original": url
                })

    if trechos_nao_conformes:
        df_nao_conformes = pd.DataFrame(trechos_nao_conformes)
        df_nao_conformes = df_nao_conformes.drop_duplicates()

        st.divider()
        st.subheader("ğŸŸ¥ Trechos identificados como possÃ­vel indÃ­cio de conduta vedada")

        # Exibe a tabela interativa (com filtro, ordenaÃ§Ã£o, etc.)
        st.dataframe(
            df_nao_conformes,
            column_config={
                "Site": st.column_config.TextColumn("Site", width="medium"),
                "Trecho": st.column_config.TextColumn("Trecho identificado", width="large"),
                "ClassificaÃ§Ã£o": st.column_config.TextColumn("Classif.", width="small"),
                "URL original": st.column_config.LinkColumn("URL", width="medium", display_text=r"https?://(.+)")
            },
            hide_index=True,
            use_container_width=True
        )

        # contador rÃ¡pido trechos
        st.caption(f"Total de trechos com nÃ£o conformidades: **{len(df_nao_conformes)}**")

        # BotÃ£o para baixar CSV
        csv = df_nao_conformes.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="ğŸ“¥ Baixar tabela como CSV",
            data=csv,
            file_name="trechos_indicio.csv",
            mime="text/csv"
        )
    else:
        st.info("Nenhum trecho classificado como 'nÃ£o conforme' foi encontrado na anÃ¡lise.")

    if not df_result.empty:
        col_esq, col_centro, col_dir = st.columns([1, 2, 1])

        with col_centro:
            fig, ax = plt.subplots(figsize=(10, 5))

            sites = df_result["Site"]
            valores = df_result["Conformidade (%)"].astype(float).clip(0, 100)

            # Cores por gradiente
            cores = plt.colormaps['viridis'](valores / 100.0)

            bars = ax.bar(sites, valores, color=cores, edgecolor='blue', linewidth=0.8)

            # RÃ³tulos com percentual
            for bar in bars:
                height = bar.get_height()
                ax.text(
                    bar.get_x() + bar.get_width() / 2,
                    height + 1,
                    f'{height:.1f}%',
                    ha='center',
                    va='bottom',
                    fontsize=8,
                    fontweight='bold'
                )

            ax.set_xlabel("")
            ax.set_ylabel("Conformidade (%)", fontsize=10)
            ax.set_title(" ğŸ“Š Grau de Conformidade dos Trechos Analisados", fontsize=10, pad=20)

            ax.tick_params(axis='x', labelsize=8, rotation=45)
            ax.tick_params(axis='y', labelsize=8)

            ax.grid(axis='y', linestyle='--', alpha=0.4)
            ax.spines['top'].set_visible(False)
            ax.spines['right'].set_visible(False)

            ax.set_ylim(0, 100)

            plt.tight_layout()
            st.pyplot(fig)

# RodapÃ©
st.markdown("---")
st.caption("Analisador de Conformidade de Conduta Vedada | Desenvolvido por Fabiana, JoÃ£o Vicente, LÃ­via, TÃºlio e YroÃ¡")



